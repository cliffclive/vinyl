{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Vinyl is a sequential deep learning model (recursive neural network or RNN) that classifies the genre (or genres) of a song based on its groove, where the groove is defined by the musical qualities of the notes played in a song most closely related to the rhythm and beat.\n",
    "\n",
    "I collect data from Spotify for playlists from close to 3,000 musical genres, and obtain audio analysis data for 100-200 songs per genre. By training a specialized RNN on a sequence of each note played in each song, I build a model that is able to identify the genres most strongly represented by a song. \n",
    "\n",
    "Genres are not well defined at a fine level of detail, and this methodology is intended to use the vague boundaries between musical genres to produce a map or genealogy of the evolution of musical styles. This is useful for understanding the history and development of music, and for helping listeners to explore new musical styles that should be similar to their tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "- Who are your customers?\n",
    "- What is the problem?\n",
    "- What solution do you propose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Plan\n",
    "- What data will you collect?\n",
    "- What models can you use to analyze it?\n",
    "- How will you know that your models work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "To build this model, I pull data from a website called [Every Noise At Once](http://everynoise.com/engenremap.html), which maps out close to 3,000 genres of music in a space that is roughly characterized by instrumentation that trends from organic to electric on the vertical axis, anda musical quality that ranges from dense and atmospheric to spiky and bouncy along the horizontal axis.\n",
    "\n",
    "Each of these genres has its own page that contains a word cloud of popular artists in the genre, as well as links to Spotify playlists with 100-200 songs that represent the genre's style. I scrape Every Noise to collect a list of playlist URIs for each genre, and then I use the Spotify API to collect audio analysis files for the songs in each playlist.\n",
    "\n",
    "*After completing this step, be sure to edit `references/data_dictionary` to include descriptions of where you obtained your data and what information it contains.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the Data Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Pipeline Tools\n",
    "\n",
    "Make sure these steps are reproducible by code. Put some thought into the directory structures and filepaths you are using to save your data, so it's easy to load files you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "import os, pickle, re, requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import functools\n",
    "\n",
    "# FUNCTIONS TO GET GENRES AND PLAYLIST LINKS FROM EVERY-NOISE-AT-ONCE\n",
    "\n",
    "def load_or_make(creator):\n",
    "    \"\"\"\n",
    "    Loads data that is pickled at filepath if filepath exists;\n",
    "    otherwise, calls creator(*args, **kwargs) to create the data \n",
    "    and pickle it at filepath.\n",
    "    Returns the data in either case.\n",
    "    \n",
    "    Inputs:\n",
    "    - filepath: path to where data is / should be stored\n",
    "    - creator: function to create data if it is not already pickled\n",
    "    - *args, **kwargs: arguments passed to creator()\n",
    "    \n",
    "    Outputs:\n",
    "    - item: the data that is stored at filepath\n",
    "    \"\"\"\n",
    "    @functools.wraps(creator)\n",
    "    def cached_creator(filepath, *args, **kwargs):\n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, 'rb') as pkl:\n",
    "                item = pickle.load(pkl)\n",
    "        else:\n",
    "            item = creator(*args, **kwargs)\n",
    "            with open(filepath, 'wb') as pkl:\n",
    "                pickle.dump(item, pkl)\n",
    "        return item\n",
    "    return cached_creator\n",
    "\n",
    "@load_or_make\n",
    "def scrape_all_links(domain, index, target_pattern):\n",
    "    \"\"\"\n",
    "    Scrapes a website and compiles a list of urls that match a target pattern.\n",
    "    \n",
    "    Inputs: \n",
    "    - domain: domain of the website you want to scrape\n",
    "    - index: path to the page that you want to scrape from `domain`\n",
    "    - target_pattern: regex that specifies the types of links you want to collect\n",
    "    \n",
    "    Outputs:\n",
    "    - target_urls: list of all the links on domain/index that match target_pattern\n",
    "    \"\"\"\n",
    "    main_page = '/'.join(['http:/', domain, index])\n",
    "    response = requests.get(main_page)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise ConnectionError(f\"Failed to connect to {main_page}.\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    target_regex = re.compile(target_pattern)\n",
    "    target_urls = ['/'.join(['http:/', domain, x['href']])\n",
    "                    for x in soup.find_all('a', {'href':target_regex})]\n",
    "\n",
    "    return target_urls\n",
    "\n",
    "@load_or_make\n",
    "def scrape_links_from_each_page(urls, target_pattern, labeler=(lambda x:x)):\n",
    "    \"\"\"\n",
    "    Loops over a list of urls and finds links that matches a target pattern from each page.\n",
    "    \n",
    "    Inputs:\n",
    "    - urls: the list of urls to scrape links from\n",
    "    - target_pattern: regex that specifies the types of links you want to collect\n",
    "    - labeler: function that parses a url and returns a label for that page\n",
    "    \n",
    "    Outputs:\n",
    "    - links: a dictionary with key/value pairs {url_label:[scraped_links]}\n",
    "    \"\"\"\n",
    "    links = {}\n",
    "\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        label = labeler(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise ConnectionError(f\"Failed to connect to {url}.\")\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "        target_regex = re.compile(target_pattern)\n",
    "        target_urls = [x['href'] for x in soup.find_all('a', {'href':target_regex})]\n",
    "\n",
    "        links[label] = target_urls\n",
    "    \n",
    "    return links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS TO GET PLAYLIST METADATA FROM SPOTIFY\n",
    "\n",
    "def get_tags(track):\n",
    "    '''\n",
    "    Parse metadata for a spotify track\n",
    "    From a user_playlist json file, a track can be found via:\n",
    "        user_playlist['tracks']['items'][i]\n",
    "    '''\n",
    "    tags =  {\n",
    "        'id': track['id'],\n",
    "        'album': track['album']['name'],\n",
    "        'track': track['track_number'],\n",
    "        'title': track['name'],\n",
    "        'artist': track['artists'][0]['name'],\n",
    "        'duration': int(track['duration_ms']/1000),\n",
    "        'preview_mp3': track['preview_url'],\n",
    "        'is_explicit': track['explicit'],\n",
    "        'isrc_number': track['external_ids'].get('isrc', ''),\n",
    "        'release_date': track['album']['release_date']\n",
    "    }\n",
    "    if track['album']['images']:\n",
    "        tags['cover_art_url'] = track['album']['images'][0]['url']\n",
    "    return tags\n",
    "\n",
    "def build_metadata_df(tracks, client):\n",
    "    #metadata = []\n",
    "    #for track in tracks['items']:\n",
    "    #    # read tags from the playlist JSON\n",
    "    #    metadata.append(get_tags(track['track']))\n",
    "    metadata = [get_tags(item['track']) for item in tracks['items'] if item['track']]\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    # add more features from the tracks' audio features JSON\n",
    "    features = client.audio_features(list(metadata_df['id']))\n",
    "    features_df = pd.DataFrame(features)\n",
    "    metadata_df = pd.merge(metadata_df, features_df)\n",
    "\n",
    "    return metadata_df\n",
    "\n",
    "def download_playlist_metadata(user, pid, pname, client):\n",
    "    # get metadata for playlist 'pname' by 'user'\n",
    "    results = client.user_playlist(user, pid, fields=\"tracks,next\")\n",
    "    tracks = results['tracks']\n",
    "\n",
    "    all_dfs = []\n",
    "    batch_df = build_metadata_df(tracks, client)\n",
    "    all_dfs.append(batch_df)\n",
    "\n",
    "    while tracks['next']:\n",
    "        tracks = client.next(tracks)\n",
    "        batch_df = build_metadata_df(tracks, client)\n",
    "        all_dfs.append(batch_df)\n",
    "    metadata = pd.concat(all_dfs)\n",
    "    metadata.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def parse_sos_pid(playlists):\n",
    "    return [x.split('/')[-1] for x in playlists if 'thesoundsofspotify' in x][0]\n",
    "\n",
    "def download_all_genres_metadata(genre_playlists, client):\n",
    "    for k,v in genre_playlists.items():\n",
    "        pname = k\n",
    "        filepath = f'../data/interim/genre_metadata/{pname}_metadata.tsv'\n",
    "        if os.path.isfile(filepath):\n",
    "            continue\n",
    "        pid = parse_sos_pid(v)\n",
    "        metadata = download_playlist_metadata('thesoundsofspotify', pid, pname, client)\n",
    "        metadata.to_csv(filepath, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Set this up so that you won't need to download datasets that you already have on your computer when you re-run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spotipy.oauth2 as oauth2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "\n",
    "def generate_token():\n",
    "    \"\"\" Generate the token. Please respect these credentials :) \"\"\"\n",
    "    credentials = oauth2.SpotifyClientCredentials(\n",
    "        client_id=os.getenv(\"SPOTIPY_CLIENT_ID\"),\n",
    "        client_secret=os.getenv(\"SPOTIPY_CLIENT_SECRET\"))\n",
    "    token = credentials.get_access_token()\n",
    "    return token\n",
    "\n",
    "token=generate_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy.util as util\n",
    "\n",
    "username='djconxn'\n",
    "\n",
    "# Cache needs to be clear to load a new token.\n",
    "try:\n",
    "    os.remove(f\".cache-{username}\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "\n",
    "def run_data_pipeline():\n",
    "    \"\"\"\n",
    "    - scrape genre page urls from everynoise.com/engenremap.html,\n",
    "        save as a list in ../data/raw/everynoise_genre_urls.pkl\n",
    "        \n",
    "    - scrape genre playlist urls from each genre page on everynoise.com,\n",
    "        save as a dictionary in ../data/raw/thesoundsofspotify_playlist_urls.pkl\n",
    "        \n",
    "    - download playlist metadata for each playlist from Spotify,\n",
    "        save as TSV files in ../data/raw/thesoundsofspotify/[genre].tsv\n",
    "        \n",
    "    - download audio_analysis files for each song in a list of playlists\n",
    "        (not necessarily all playlists because there are 100s of 1000s in the full set)\n",
    "        save as audio_analysis dictionaries in ../data/raw/audio_analysis/[song_uri].pkl\n",
    "    \n",
    "    TODO: include a progress indicator?\n",
    "    \"\"\"\n",
    "    genre_urls = scrape_all_links(\n",
    "        '../data/raw/everynoise_genre_urls.pkl',\n",
    "        domain='everynoise.com', \n",
    "        index='engenremap.html', \n",
    "        target_pattern='engenremap-[a-z]*')\n",
    "    \n",
    "    genre_playlists = scrape_links_from_each_page(\n",
    "        '../data/raw/thesoundsofspotify_playlist_urls.pkl',\n",
    "        urls=genre_urls,\n",
    "        labeler=(lambda url: url.split('/')[-1].split('-')[-1].split('.')[0]),\n",
    "        target_pattern='open.spotify.com')\n",
    "    \n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    \n",
    "    download_all_genres_metadata(genre_playlists, sp)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T19:50:29.573356Z",
     "start_time": "2019-06-04T19:50:29.560167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2911"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre_playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T19:57:23.759275Z",
     "start_time": "2019-06-04T19:50:53.821423Z"
    }
   },
   "outputs": [],
   "source": [
    "run_data_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "So far I have:\n",
    "- a directory full of `genre_metadata` DataFrames, the id of which maps to the filenames in...\n",
    "- a directory full of preview mp3s for songs in each of the genre playlists.\n",
    "\n",
    "I want to convert the audio data from these mp3s into features that I can use to train a model to classify new songs as representing one of the genres in my training set.\n",
    "\n",
    "For my MVP model, I'll work with [MFCC's](https://musicinformationretrieval.com/mfcc.html), which are a small set of features (usually about 10-20) which concisely describe the overall shape of a spectral envelope. In MIR, it is often used to describe timbre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:51:01.683496Z",
     "start_time": "2019-06-12T21:51:01.680558Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:51:03.834946Z",
     "start_time": "2019-06-12T21:51:03.831893Z"
    }
   },
   "outputs": [],
   "source": [
    "# get paths for all genre metadataframes\n",
    "genre_metadata_dir = \"../data/interim/genre_metadata\"\n",
    "sample_mp3_dir = \"../data/raw/mp3s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:51:07.449234Z",
     "start_time": "2019-06-12T21:51:07.440631Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_genre_songids(genre_metadata_dir, limit=None):\n",
    "    genre_songids_dict = {}\n",
    "    files = os.listdir(genre_metadata_dir)\n",
    "    for x in files:\n",
    "        genre = x.replace('_metadata.tsv', '')\n",
    "        if genre == x:\n",
    "            # filename did not contain _metadata.tsv\n",
    "            continue\n",
    "        metadata_path = os.path.join(genre_metadata_dir, x)\n",
    "        songids = list(pd.read_csv(metadata_path, sep='\\t').dropna()['id'])\n",
    "        if limit:\n",
    "            songids = songids[:limit]\n",
    "        # shuffle the list of ids for safer train/test splits\n",
    "        random.shuffle(songids)\n",
    "        genre_songids_dict[genre] = songids\n",
    "    return genre_songids_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:51:09.870333Z",
     "start_time": "2019-06-12T21:51:09.583704Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/interim/genre_metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-179593a4527c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenre_songids_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_genre_songids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_metadata_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#, limit=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e9dd17c8a129>\u001b[0m in \u001b[0;36mget_genre_songids\u001b[0;34m(genre_metadata_dir, limit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_genre_songids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_metadata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgenre_songids_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_metadata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mgenre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_metadata.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/interim/genre_metadata'"
     ]
    }
   ],
   "source": [
    "genre_songids_dict = get_genre_songids(genre_metadata_dir)  #, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End goal: dataframe with \n",
    "# 12 feature columns, a label column, and an id column\n",
    "# Perform train/test split on label+id columns, (must convert id to int)\n",
    "# then use id split to extract train/test matrices from dataframe\n",
    "genre_features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_from_mp3(songid, *args, **kwargs):\n",
    "    filepath = os.path.join(sample_mp3_dir, songid) + \".mp3\"\n",
    "    x, sr = librosa.load(filepath)\n",
    "    mfcc = pd.DataFrame(librosa.feature.mfcc(x, sr, *args, **kwargs).T)\n",
    "    mfcc['id'] = songid\n",
    "    return mfcc\n",
    "\n",
    "def collect_genre_mfccs(genre_songids_dict, n_mfcc=12):\n",
    "    genre_mfccs = []\n",
    "    for genre in genre_songids_dict.keys():\n",
    "        mfccs = [get_mfcc_from_mp3(x, n_mfcc=n_mfcc)\n",
    "                 for x in genre_songids_dict[genre]]\n",
    "        genre_mfcc_df = pd.concat(mfccs)\n",
    "        genre_mfcc_df['genre'] = genre\n",
    "        genre_mfccs.append(genre_mfcc_df)\n",
    "    genre_mfccs = pd.concat(genre_mfccs)\n",
    "    genre_mfccs.reset_index(inplace=True, drop=True)\n",
    "    return genre_mfccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_features = collect_genre_mfccs(genre_songids_dict)\n",
    "#test_genre_features = collect_genre_mfccs(test_genre_songpaths_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T21:50:33.995539Z",
     "start_time": "2019-06-12T21:50:27.279278Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 3 random songs\n",
    "songid_opera = random.choice(genre_songids_dict['opera'])\n",
    "filename_opera = os.path.join(sample_mp3_dir, songid_opera) + \".mp3\"\n",
    "x_opera, sr_opera = librosa.load(filename_opera)\n",
    "\n",
    "songid_techno = random.choice(genre_songids_dict['techno'])\n",
    "filename_techno = os.path.join(sample_mp3_dir, songid_techno) + \".mp3\"\n",
    "x_techno, sr_techno = librosa.load(filename_techno)\n",
    "\n",
    "songid_kpop = random.choice(genre_songids_dict['kpop'])\n",
    "filename_kpop = os.path.join(sample_mp3_dir, songid_kpop) + \".mp3\"\n",
    "x_kpop, sr_kpop = librosa.load(filename_kpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot waveform\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x_opera, sr_opera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_opera, rate=sr_opera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot waveform\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x_techno, sr_techno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_techno, rate=sr_techno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot waveform\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x_kpop, sr_kpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_kpop, rate=sr_kpop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Features for Predictive Patterns\n",
    "\n",
    "In a regression model, we are looking for clear relationships between our features and targets.\n",
    "\n",
    "In a classification model, we are looking for features that separate the population into distinct distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(genre_features, hue='genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *What did you learn about your data?*\n",
    "- *Does it look like there are clear patterns and relationships among your features that will allow you to make good predictions?*\n",
    "- *Which features do you think will be most helpful?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithms that you are considering. How do they work? Why are they good choices for this data and problem space?*\n",
    "\n",
    "*What nuances in the data will you have to be aware of in order to avoid introducing bias to your model? What steps will you need to take to prevent overfitting? What risks are there for data leakage?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are taking many observations from each song, \n",
    "# we don't want songs to appear in both the train and test set.\n",
    "ids_genres = genre_features[['id', 'genre']].drop_duplicates()\n",
    "\n",
    "id_train, id_test, y_train, y_test = train_test_split(\n",
    "    ids_genres['id'], ids_genres['genre'], stratify=ids_genres['genre'])\n",
    "\n",
    "train_select = genre_features['id'].isin(id_train)\n",
    "\n",
    "X_train = genre_features[train_select]\n",
    "X_test = genre_features[~train_select]\n",
    "genre_train = genre_features[train_select]['genre']\n",
    "genre_test = genre_features[~train_select]['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_encoder = LabelEncoder()\n",
    "genre_encoder.fit(genre_features['genre'])\n",
    "y_train = genre_encoder.transform(genre_train)\n",
    "y_test = genre_encoder.transform(genre_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "feature_scaler.fit(X_train.iloc[:,:-2])\n",
    "X_train_scaled = feature_scaler.transform(X_train.iloc[:,:-2])\n",
    "X_test_scaled = feature_scaler.transform(X_test.iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear_svc = sklearn.svm.LinearSVC(max_iter=10000)\n",
    "model_linear_svc.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What looks to have been the most successful design choices? What pain points are you running into? What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_linear_svc.score(X_test_scaled, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_linear_svc.predict(X_test_scaled)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "conf_df = pd.DataFrame(conf_mat, index=genre_encoder.classes_+'_true', \n",
    "                       columns=genre_encoder.classes_+'_pred')\n",
    "\n",
    "sns.heatmap(conf_df.div(conf_df.sum(axis=1), axis=0), annot=True)\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have over 1000 mfcc's per song, and one prediction for each of these\n",
    "# Let's convert our predictions to the most commonly predicted genre\n",
    "# out of >1000 predictions per song.\n",
    "results = pd.DataFrame({'true':y_test, 'pred':y_pred, \n",
    "                        'id':genre_features[~train_select]['id'],\n",
    "                        'genre':genre_features[~train_select]['genre']})\n",
    "modes = results.groupby(['true', 'id', 'genre']).agg(pd.Series.mode)\n",
    "\n",
    "conf_mat = confusion_matrix(modes.index.codes[0], modes.pred)\n",
    "\n",
    "conf_df = pd.DataFrame(conf_mat, index=genre_encoder.classes_+'_true', \n",
    "                       columns=genre_encoder.classes_+'_pred')\n",
    "\n",
    "sns.heatmap(conf_df.div(conf_df.sum(axis=1), axis=0), annot=True)\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = modes.reset_index()\n",
    "kpop_pred_techno = modes[(modes['true']==0) & (modes['pred']==2)]['id'].iloc[0]\n",
    "techno_pred_kpop = modes[(modes['true']==2) & (modes['pred']==0)]['id'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songid_techno = techno_pred_kpop\n",
    "filename_techno = os.path.join(sample_mp3_dir, songid_techno) + \".mp3\"\n",
    "x_techno, sr_techno = librosa.load(filename_techno)\n",
    "\n",
    "songid_kpop = kpop_pred_techno\n",
    "filename_kpop = os.path.join(sample_mp3_dir, songid_kpop) + \".mp3\"\n",
    "x_kpop, sr_kpop = librosa.load(filename_kpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is techno, classified as k-pop\n",
    "ipd.Audio(x_techno, rate=sr_techno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is k-pop, classified as techno\n",
    "ipd.Audio(x_kpop, rate=sr_kpop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNterpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strengths and Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Else Can We Do?\n",
    "\n",
    "- try new models, using cross-validation\n",
    "- many observations per song: stacked model to classify from output probabilities\n",
    "- engineer new audio features (check librosa docs, other audio analysis or DSP libraries, mir.com tutorials)\n",
    "- engineer feature on MFCC series, create one observation per song\n",
    "- use deep learning sequence models\n",
    "- topic modeling\n",
    "\n",
    "Other features:\n",
    "- https://librosa.github.io/librosa/generated/librosa.core.load.html\n",
    "- https://musicinformationretrieval.com/energy.html\n",
    "- https://librosa.github.io/librosa/generated/librosa.feature.tempogram.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
