{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T18:58:14.670459Z",
     "start_time": "2019-12-17T18:58:08.007172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import spotipy\n",
    "import os, requests, time, random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.obtain.spotify_metadata import generate_token, download_playlist_metadata\n",
    "from src.vinyl.audio_downloader import download_preview_mp3\n",
    "from src.vinyl.build_datasets import sample_non_zouk_songs\n",
    "from src.vinyl.build_datasets import extract_features\n",
    "from src.vinyl.build_datasets import build_dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import logging\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load New Data, Retrain and Re-evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T18:58:14.679628Z",
     "start_time": "2019-12-17T18:58:14.673415Z"
    }
   },
   "outputs": [],
   "source": [
    "features_dict = {\n",
    "    librosa.feature.mfcc : {'n_mfcc':13},\n",
    "    librosa.feature.spectral_centroid : {},\n",
    "    librosa.feature.chroma_stft : {'n_chroma':12},\n",
    "    librosa.feature.spectral_contrast : {'n_bands':6},\n",
    "    #librosa.feature.tempogram : {'win_length':192}\n",
    "}\n",
    "\n",
    "model_save_path = \"models/zouk_classifier_spectral_LSTM3.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Positive Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T18:58:15.120978Z",
     "start_time": "2019-12-17T18:58:14.683664Z"
    }
   },
   "outputs": [],
   "source": [
    "zoukables_metadata_path = 'data/interim/genre_metadata/zoukables_metadata.tsv'\n",
    "zouk = pd.read_csv(zoukables_metadata_path, sep='\\t')\n",
    "zouk_songs = zouk['id'].tolist()\n",
    "\n",
    "zouk_features_path = \"data/processed/zoukable_spectral.npy\"\n",
    "zouk_data = np.load(zouk_features_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T19:16:57.672793Z",
     "start_time": "2019-12-17T18:58:15.123425Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_mp3_dir = 'data/raw/mp3s'\n",
    "metadata_dir = \"data/interim/genre_metadata\"\n",
    "genres = os.listdir(metadata_dir)\n",
    "genres.remove(\"zoukables_metadata.tsv\")\n",
    "\n",
    "n = zouk.shape[0]\n",
    "non_zouk_songs, sample_urls = sample_non_zouk_songs(n, genres, metadata_dir)\n",
    "\n",
    "non_zouk_data = build_dataset(non_zouk_songs, sample_urls, sample_mp3_dir, features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T19:16:57.707540Z",
     "start_time": "2019-12-17T19:16:57.689947Z"
    }
   },
   "outputs": [],
   "source": [
    "target = np.array([1] * len(zouk_songs) + [0] * len(non_zouk_songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train/Test Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T19:16:59.215206Z",
     "start_time": "2019-12-17T19:16:57.711470Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((zouk_data, non_zouk_data))\n",
    "\n",
    "train_idx, test_idx, y_train, y_test = train_test_split(\n",
    "    range(X.shape[0]), target, test_size=0.33, random_state=42, stratify=target)\n",
    "\n",
    "X_train = X[train_idx,:,:]\n",
    "X_test = X[test_idx,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/cliffclive/miniconda3/envs/vinyl/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 597 samples, validate on 200 samples\n",
      "Epoch 1/400\n",
      "597/597 [==============================] - 207s 347ms/step - loss: 0.5579 - acc: 0.7320 - val_loss: 0.6210 - val_acc: 0.6750\n",
      "Epoch 2/400\n",
      "597/597 [==============================] - 207s 346ms/step - loss: 0.5638 - acc: 0.7152 - val_loss: 0.6210 - val_acc: 0.6750\n",
      "Epoch 3/400\n",
      "597/597 [==============================] - 201s 337ms/step - loss: 0.5802 - acc: 0.6951 - val_loss: 0.6210 - val_acc: 0.6750\n",
      "Epoch 4/400\n",
      "597/597 [==============================] - 189s 316ms/step - loss: 0.5693 - acc: 0.7085 - val_loss: 0.6209 - val_acc: 0.6750\n",
      "Epoch 5/400\n",
      "597/597 [==============================] - 180s 301ms/step - loss: 0.5695 - acc: 0.7085 - val_loss: 0.6208 - val_acc: 0.6750\n",
      "Epoch 6/400\n",
      "597/597 [==============================] - 181s 303ms/step - loss: 0.5655 - acc: 0.7152 - val_loss: 0.6208 - val_acc: 0.6750\n",
      "Epoch 7/400\n",
      "597/597 [==============================] - 190s 318ms/step - loss: 0.5739 - acc: 0.7085 - val_loss: 0.6208 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 8/400\n",
      "597/597 [==============================] - 181s 302ms/step - loss: 0.5500 - acc: 0.7303 - val_loss: 0.6207 - val_acc: 0.6750\n",
      "Epoch 9/400\n",
      "597/597 [==============================] - 177s 297ms/step - loss: 0.5571 - acc: 0.7253 - val_loss: 0.6207 - val_acc: 0.6750\n",
      "Epoch 10/400\n",
      "597/597 [==============================] - 179s 300ms/step - loss: 0.5597 - acc: 0.7169 - val_loss: 0.6207 - val_acc: 0.6750\n",
      "Epoch 11/400\n",
      "597/597 [==============================] - 179s 299ms/step - loss: 0.5569 - acc: 0.7136 - val_loss: 0.6207 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 12/400\n",
      "597/597 [==============================] - 2878s 5s/step - loss: 0.5708 - acc: 0.7052 - val_loss: 0.6206 - val_acc: 0.6750\n",
      "Epoch 13/400\n",
      "597/597 [==============================] - 182s 305ms/step - loss: 0.5493 - acc: 0.7253 - val_loss: 0.6206 - val_acc: 0.6750\n",
      "Epoch 14/400\n",
      "597/597 [==============================] - 196s 328ms/step - loss: 0.5547 - acc: 0.7186 - val_loss: 0.6206 - val_acc: 0.6750\n",
      "Epoch 15/400\n",
      "597/597 [==============================] - 208s 349ms/step - loss: 0.5625 - acc: 0.7085 - val_loss: 0.6206 - val_acc: 0.6750\n",
      "Epoch 16/400\n",
      "597/597 [==============================] - 195s 327ms/step - loss: 0.5742 - acc: 0.6951 - val_loss: 0.6205 - val_acc: 0.6750\n",
      "Epoch 17/400\n",
      "597/597 [==============================] - 181s 303ms/step - loss: 0.5624 - acc: 0.7203 - val_loss: 0.6205 - val_acc: 0.6750\n",
      "Epoch 18/400\n",
      "597/597 [==============================] - 184s 309ms/step - loss: 0.5693 - acc: 0.7085 - val_loss: 0.6205 - val_acc: 0.6750\n",
      "Epoch 19/400\n",
      "597/597 [==============================] - 180s 302ms/step - loss: 0.5462 - acc: 0.7504 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 20/400\n",
      "597/597 [==============================] - 196s 328ms/step - loss: 0.5741 - acc: 0.7069 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 21/400\n",
      "597/597 [==============================] - 198s 331ms/step - loss: 0.5682 - acc: 0.7136 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 22/400\n",
      "597/597 [==============================] - 198s 332ms/step - loss: 0.5675 - acc: 0.7152 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 23/400\n",
      "597/597 [==============================] - 193s 323ms/step - loss: 0.5678 - acc: 0.7186 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 24/400\n",
      "597/597 [==============================] - 182s 304ms/step - loss: 0.5702 - acc: 0.7119 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 25/400\n",
      "597/597 [==============================] - 208s 349ms/step - loss: 0.5618 - acc: 0.7152 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 26/400\n",
      "597/597 [==============================] - 187s 313ms/step - loss: 0.5604 - acc: 0.7286 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 27/400\n",
      "597/597 [==============================] - 176s 295ms/step - loss: 0.5802 - acc: 0.6985 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 28/400\n",
      "597/597 [==============================] - 178s 298ms/step - loss: 0.5567 - acc: 0.7270 - val_loss: 0.6204 - val_acc: 0.6750\n",
      "Epoch 29/400\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "batch_size = 35  # num of training examples per minibatch\n",
    "num_epochs = 400\n",
    "\n",
    "model = keras.models.load_model(model_save_path)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, \n",
    "          epochs=num_epochs, validation_split=.25, verbose=1,\n",
    "          callbacks=[\n",
    "              keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True),\n",
    "              keras.callbacks.ReduceLROnPlateau(factor=.5, patience=3, verbose=1),])\n",
    "\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.024Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nTesting ...\")\n",
    "score, accuracy = model.evaluate(\n",
    "    X_test, y_test, batch_size=batch_size, verbose=1\n",
    ")\n",
    "print(\"Test loss:  \", score)\n",
    "print(\"Test accuracy:  \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zouk classifier LSTM3 (spectral + tempo):\n",
    "- `Test Accuracy 1`: 0.7806\n",
    "- `Test Accuracy 2`: 0.7398\n",
    "- `Test Accuracy 3`: 0.6990\n",
    "- `Test Accuracy 4`: 0.7730\n",
    "- `Test Accuracy 5`: 0.7397\n",
    "- `Test Accuracy 6`: 0.7449\n",
    "- `Test Accuracy 7`: 0.7474\n",
    "\n",
    "### zouk classifier LSTM3 (spectral only):\n",
    "- `Test Accuracy 1`: 0.8092\n",
    "- `Test Accuracy 2`: 0.8117\n",
    "- `Test Accuracy 3`: 0.8168\n",
    "- `Test Accuracy 4`: 0.7710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "#### More Data\n",
    "- Start listening to the False Positives and see if they should be included in the Zouk playlist.\n",
    "- Listen to False Negatives and see if I need to remove anything from Zouk Playlist.\n",
    "- Make plans to build an app to crowdsource this work.\n",
    "\n",
    "#### More Models\n",
    "- LSTMs (add a layer, remove a layer).\n",
    "- CNNs (including VGG16).\n",
    "- Convolutional LSTMs.\n",
    "- XGBoost on Spotify Audio Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.028Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.030Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_bool = y_pred > 0.65\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.034Z"
    }
   },
   "outputs": [],
   "source": [
    "all_songs = pd.DataFrame({'song_id':zouk_songs + non_zouk_songs,\n",
    "                          'target':target})\n",
    "\n",
    "trainers = all_songs.iloc[train_idx,:].reset_index()\n",
    "\n",
    "sample0 = trainers[trainers.target==0].sample(10).index\n",
    "sample1 = trainers[trainers.target==1].sample(10).index\n",
    "sample_idx = sample0.append(sample1)\n",
    "samples = trainers.loc[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.037Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train[sample_idx,:])\n",
    "y_pred_bool = y_pred > 0.75\n",
    "samples['prediction'] = y_pred_bool.astype(int)\n",
    "print(classification_report(samples.target, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to False Positives, False Negatives\n",
    "#### TODO: look up song_id, artist, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-17T18:58:08.046Z"
    }
   },
   "outputs": [],
   "source": [
    "fp_index = samples[(samples.target==0) & (samples.prediction==1)].index\n",
    "fn_index = samples[(samples.target==1) & (samples.prediction==0)].index\n",
    "\n",
    "print(\"False Positives:\")\n",
    "print(\"(add these to the list?)\")\n",
    "for i in fp_index:\n",
    "    filepath = os.path.join(sample_mp3_dir, (samples['song_id'][i] + '.mp3'))\n",
    "    ipd.display(ipd.Audio(filepath))\n",
    "\n",
    "print(\"~\" * 32)\n",
    "\n",
    "print(\"False Negatives:\")\n",
    "print(\"(remove these from the list?)\")\n",
    "for i in fn_index:\n",
    "    filepath = os.path.join(sample_mp3_dir, (samples['song_id'][i] + '.mp3'))\n",
    "    ipd.display(ipd.Audio(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [Keras docs](https://keras.io/)\n",
    "- [Librosa docs](https://librosa.github.io/librosa/index.html)\n",
    "- [Spotipy docs](https://spotipy.readthedocs.io)\n",
    "- [ruohoruotsi: LSTM Music Genre Classification on GitHub](https://github.com/ruohoruotsi/LSTM-Music-Genre-Classification)\n",
    "- [Music Genre classification using a hierarchical Long Short Term Memory (LSTM) Model](http://www.cs.cuhk.hk/~khwong/p186_acm_00_main_lstm_music_rev5.pdf)\n",
    "- [Using CNNs and RNNs for Music Genre Recognition](https://towardsdatascience.com/using-cnns-and-rnns-for-music-genre-recognition-2435fb2ed6af) [(GitHub)](https://github.com/priya-dwivedi/Music_Genre_Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vinyl",
   "language": "python",
   "name": "vinyl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
